<template name="contact">
  <div class="contact anchorpoint">
    <div class="container-fluid">
      <div class="row">
        <div class="col-sm-12">
          <h1>Contact</h1>
          <p>
            Unmanned aerial vehicles (UAVs) have become an interesting and important area of research.  UAVs are used in military as well as civilian applications, such as search and rescue, structure inspection, and environmental surveying (Bio-Inspired).  The safety of UAVs in a variety of applications is a continuous concern.  Visual homing--the ability of the UAV to return to its starting position after having explored an area--could continue improving safety and practicality by preventing users from having to search in potentially dangerous areas to retrieve UAVs. Much of the research on visual homing has been implemented on ground robots.  Though research on visual navigation has been done on UAVs, these methods can be improved upon by combining techniques used across the literature.  Visual homing in the complete absence of GPS information and without the help of other navigation tools is an important problem to solve as it could continue to make UAVs easier and safer to use in a variety of applications.
            Visual homing for unmanned aerial vehicles (UAVs) has become an important topic of research due to the flaws of GPS based navigation.  A third party can use a jammer to intercept satellite communications to the UAV, and then send incorrect coordinates to the aircraft.  By sending false coordinates from the jammer to the UAV, a third party would be able to hijack the the flight path of the aircraft (Jamming Research).  Visual homing can add a layer of security to UAV navigation by providing an alternative to easily compromised GPS signals.
            Visual homing also offers advantages over other navigation techniques.  Cameras can replace bulkier sensors, which is important because of the small payload of UAVs, and are less expensive.  Computer vision can also be used for multiple tasks, with the camera serving as the primary sensor for navigation as well as other tasks (Bio-Inspired).  Visual homing offers a sparse representation of the environment, often through a number of snapshots taken by the UAV during its flight.  These images can be used for navigation and are independent of maps, which may be imprecise.  Path planning and navigation based on snapshots can be done with relatively low computation (Visual Homing rom Scale).  Furthermore, the Federal Aviation Administration (FAA) regulations typically assume that pilots rely on vision, specifically that pilots must “see and avoid” other aircraft (Computer Vision).  Visual navigation of UAVs can offer a distinct advantage over other navigation techniques.
            Problems similar to visual homing include visual navigation or visual target finding.  In the event of a GPS jamming or GPS failure, computer vision can be used to approximate the position of the ground robot or UAV, making navigation possible (Intelligent System, Image Based System).  In research conducted by ChengHao, et al., ground images, or snapshots, were stitched together to create a map of the environment.  By combining onboard cameras and an inertial navigation system (INS), the position of the UAV could be approximated (UAV Navigation Aided).  Similarly, in UAV swarms, communication between drones can allow for accurate position estimation and navigation when some of the drones do not have a working GPS (Cooperative UAV Navigation).  These and similar experiments rely on previous GPS information for navigation (New Approach for Reliable).  Though the techniques used to address the problem of visual navigation can be applied to visual homing, our project differs in that we will research visual homing in the complete absence of GPS information.
            Visual target finding is another problem related to visual homing.  In research done by Cumbo, et al., the homing strategies of bees inspired the techniques through which a ground robot was able to learn to use landmarks in the environment to approach a particular target.  Even when the target was not present, the robot could navigate to the area the target had been based on the landmarks.  In some cases, when the target was moved, the robot used landmarks to approach the area and found the target from there.  However, when the landmarks were removed, the ground robot could not find the target unless its starting position was relatively close to the target (Bee-inspired Landmark).  In this case, the learned target finding was specific to the environment.  Once the environment changed by removing the landmarks, the ground robot often could not find its target.  While visual homing can be thought of as visual target finding--with the home position being the target--our approach to visual homing will be more robust in that it will not be environment specific.
          </p>
        </div>
      </div>
    </div>
  </div>
</template>
